[2025-07-18T11:32:18.773+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:32:18.783+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:32:18.783+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:32:18.783+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T11:32:18.783+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:32:18.793+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T11:32:18.798+0000] {standard_task_runner.py:55} INFO - Started process 176 to run task
[2025-07-18T11:32:18.802+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpk6w2f74r']
[2025-07-18T11:32:18.804+0000] {standard_task_runner.py:83} INFO - Job 3: Subtask ingest_data
[2025-07-18T11:32:18.874+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 8ff7e281da47
[2025-07-18T11:32:18.951+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T11:32:18.952+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T11:32:18.953+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T11:32:18.970+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T11:32:19.046+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T11:32:19.048+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T11:32:19.048+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T11:32:19.048+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T11:32:19.049+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T11:32:19.056+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T11:32:19.059+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T113218, end_date=20250718T113219
[2025-07-18T11:32:19.068+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 176)
[2025-07-18T11:32:19.111+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T11:32:19.130+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T11:36:57.786+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:36:57.792+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:36:57.792+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:36:57.792+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T11:36:57.792+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:36:57.801+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T11:36:57.805+0000] {standard_task_runner.py:55} INFO - Started process 178 to run task
[2025-07-18T11:36:57.810+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpdm5almth']
[2025-07-18T11:36:57.815+0000] {standard_task_runner.py:83} INFO - Job 3: Subtask ingest_data
[2025-07-18T11:36:57.870+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host ccdcdc2eaebf
[2025-07-18T11:36:57.919+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T11:36:57.920+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T11:36:57.921+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T11:36:57.926+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T11:36:57.993+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T11:36:57.995+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T11:36:57.995+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T11:36:57.995+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T11:36:57.995+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T11:36:58.002+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T11:36:58.005+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T113657, end_date=20250718T113658
[2025-07-18T11:36:58.011+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 3 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 178)
[2025-07-18T11:36:58.031+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T11:36:58.050+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T11:47:08.755+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:47:08.761+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:47:08.763+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:47:08.764+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T11:47:08.764+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:47:08.769+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T11:47:08.781+0000] {standard_task_runner.py:55} INFO - Started process 176 to run task
[2025-07-18T11:47:08.783+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp6fiey1a7']
[2025-07-18T11:47:08.788+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T11:47:08.831+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 24fa8db10c0a
[2025-07-18T11:47:08.869+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T11:47:08.870+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T11:47:08.871+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T11:47:08.879+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T11:47:09.001+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T11:47:09.002+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 3, in <module>
[2025-07-18T11:47:09.005+0000] {subprocess.py:93} INFO -     from src.data.ingestion import DataIngestor
[2025-07-18T11:47:09.005+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'src'
[2025-07-18T11:47:09.020+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T11:47:09.029+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 196, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T11:47:09.032+0000] {taskinstance.py:1322} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T114708, end_date=20250718T114709
[2025-07-18T11:47:09.040+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 176)
[2025-07-18T11:47:09.046+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T11:47:09.058+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T11:52:19.804+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:52:19.815+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:52:19.815+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:52:19.816+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T11:52:19.816+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:52:19.823+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T11:52:19.826+0000] {standard_task_runner.py:55} INFO - Started process 175 to run task
[2025-07-18T11:52:19.828+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpw_071u58']
[2025-07-18T11:52:19.833+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T11:52:19.883+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 516d570cb05f
[2025-07-18T11:52:19.920+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T11:52:19.921+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T11:52:19.922+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T11:52:19.930+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T11:52:20.768+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T11:52:20.769+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T11:52:20.769+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T11:52:20.769+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T11:52:20.770+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T11:52:20.809+0000] {subprocess.py:93} INFO - Primary config directory not found.
[2025-07-18T11:52:20.809+0000] {subprocess.py:93} INFO - Check that the config directory '/app/config' exists and readable
[2025-07-18T11:52:20.809+0000] {subprocess.py:93} INFO - 
[2025-07-18T11:52:20.809+0000] {subprocess.py:93} INFO - Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[2025-07-18T11:52:20.908+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T11:52:20.917+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 196, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T11:52:20.921+0000] {taskinstance.py:1322} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T115219, end_date=20250718T115220
[2025-07-18T11:52:20.936+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 175)
[2025-07-18T11:52:20.963+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T11:52:20.985+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T11:54:34.814+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:54:34.820+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T11:54:34.820+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:54:34.821+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T11:54:34.821+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T11:54:34.829+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T11:54:34.833+0000] {standard_task_runner.py:55} INFO - Started process 174 to run task
[2025-07-18T11:54:34.836+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpqar13vp5']
[2025-07-18T11:54:34.838+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T11:54:34.893+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 71b03233e140
[2025-07-18T11:54:34.945+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T11:54:34.946+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T11:54:34.947+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T11:54:34.953+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T11:54:35.693+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T11:54:35.694+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T11:54:35.694+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T11:54:35.694+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T11:54:35.694+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T11:54:35.790+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T11:54:35.790+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T11:54:35.793+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T11:54:38.264+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T11:54:38.264+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T11:54:38.374+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T11:54:38.393+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T115434, end_date=20250718T115438
[2025-07-18T11:54:38.411+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T11:54:38.430+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T12:19:23.326+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T12:19:23.333+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T12:19:23.333+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T12:19:23.333+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T12:19:23.334+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T12:19:23.340+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T12:19:23.344+0000] {standard_task_runner.py:55} INFO - Started process 365 to run task
[2025-07-18T12:19:23.352+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpq_tl_3gg']
[2025-07-18T12:19:23.358+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T12:19:23.410+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 0a70033a54ea
[2025-07-18T12:19:23.455+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T12:19:23.456+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T12:19:23.457+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T12:19:23.462+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T12:19:24.387+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T12:19:24.387+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T12:19:24.387+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T12:19:24.388+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T12:19:24.388+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T12:19:24.480+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T12:19:24.481+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T12:19:24.481+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T12:19:26.503+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T12:19:26.504+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T12:19:26.595+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T12:19:26.618+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T121923, end_date=20250718T121926
[2025-07-18T12:19:26.644+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T12:19:26.665+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T13:33:27.106+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T13:33:27.112+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T13:33:27.113+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T13:33:27.113+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T13:33:27.113+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T13:33:27.119+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T13:33:27.122+0000] {standard_task_runner.py:55} INFO - Started process 180 to run task
[2025-07-18T13:33:27.132+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmprz8mxi7c']
[2025-07-18T13:33:27.135+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T13:33:27.181+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 8169abd6c4f3
[2025-07-18T13:33:27.221+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T13:33:27.222+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T13:33:27.223+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T13:33:27.230+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T13:33:28.059+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T13:33:28.060+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T13:33:28.060+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T13:33:28.060+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T13:33:28.060+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T13:33:28.156+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T13:33:28.161+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T13:33:28.162+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T13:33:29.985+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T13:33:29.986+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T13:33:30.097+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T13:33:30.117+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T133327, end_date=20250718T133330
[2025-07-18T13:33:30.163+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T13:33:30.178+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:02:55.586+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:02:55.592+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:02:55.592+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:02:55.592+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:02:55.592+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:02:55.600+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:02:55.603+0000] {standard_task_runner.py:55} INFO - Started process 181 to run task
[2025-07-18T14:02:55.606+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpvqpqnx3r']
[2025-07-18T14:02:55.608+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:02:55.656+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host e85c054be2df
[2025-07-18T14:02:55.699+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:02:55.700+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:02:55.700+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:02:55.706+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:02:55.826+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:02:55.826+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 3, in <module>
[2025-07-18T14:02:55.826+0000] {subprocess.py:93} INFO -     from src.data.ingestion import DataIngestor
[2025-07-18T14:02:55.827+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'src'
[2025-07-18T14:02:55.841+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:02:55.848+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 196, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:02:55.851+0000] {taskinstance.py:1322} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T140255, end_date=20250718T140255
[2025-07-18T14:02:55.858+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 181)
[2025-07-18T14:02:55.870+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:02:55.884+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:07:42.658+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:07:42.665+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:07:42.665+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:07:42.665+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:07:42.665+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:07:42.671+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:07:42.674+0000] {standard_task_runner.py:55} INFO - Started process 210 to run task
[2025-07-18T14:07:42.676+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpcx9x_n_i']
[2025-07-18T14:07:42.677+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:07:42.728+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host f6bb4ae5b7b3
[2025-07-18T14:07:42.771+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:07:42.772+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:07:42.773+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:07:42.779+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:07:43.685+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T14:07:43.687+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T14:07:43.688+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T14:07:43.689+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T14:07:43.690+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T14:07:43.940+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T14:07:43.941+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T14:07:43.941+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T14:07:45.576+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T14:07:45.577+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T14:07:45.704+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T14:07:45.719+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T140742, end_date=20250718T140745
[2025-07-18T14:07:45.759+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T14:07:45.783+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:25:39.236+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:25:39.241+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:25:39.242+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:25:39.242+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:25:39.243+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:25:39.250+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:25:39.253+0000] {standard_task_runner.py:55} INFO - Started process 186 to run task
[2025-07-18T14:25:39.256+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmparuua3k9']
[2025-07-18T14:25:39.258+0000] {standard_task_runner.py:83} INFO - Job 3: Subtask ingest_data
[2025-07-18T14:25:39.302+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 462761df47da
[2025-07-18T14:25:39.338+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:25:39.339+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:25:39.339+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:25:39.345+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:25:40.087+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T14:25:40.087+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T14:25:40.087+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T14:25:40.088+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T14:25:40.088+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T14:25:40.192+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T14:25:40.193+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T14:25:40.195+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T14:25:41.937+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T14:25:41.937+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T14:25:42.099+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T14:25:42.141+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T142539, end_date=20250718T142542
[2025-07-18T14:25:42.195+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T14:25:42.236+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:31:24.222+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:31:24.230+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:31:24.231+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:31:24.231+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:31:24.232+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:31:24.240+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:31:24.247+0000] {standard_task_runner.py:55} INFO - Started process 174 to run task
[2025-07-18T14:31:24.254+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpq82j6qlc']
[2025-07-18T14:31:24.258+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:31:24.301+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host e601907df341
[2025-07-18T14:31:24.341+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:31:24.344+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:31:24.345+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:31:24.351+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:31:25.154+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T14:31:25.154+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T14:31:25.154+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T14:31:25.154+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T14:31:25.155+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T14:31:25.245+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T14:31:25.246+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T14:31:25.246+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T14:31:26.838+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T14:31:26.839+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T14:31:27.070+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T14:31:27.113+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T143124, end_date=20250718T143127
[2025-07-18T14:31:27.176+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T14:31:27.206+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:41:55.505+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:41:55.511+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:41:55.511+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:41:55.511+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:41:55.512+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:41:55.520+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:41:55.523+0000] {standard_task_runner.py:55} INFO - Started process 187 to run task
[2025-07-18T14:41:55.526+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp7hiit1cr']
[2025-07-18T14:41:55.528+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:41:55.582+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 44fead07a06b
[2025-07-18T14:41:55.664+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:41:55.665+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:41:55.665+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:41:55.671+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:41:55.741+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:41:55.741+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:41:55.742+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:41:55.742+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:41:55.743+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:41:55.750+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:41:55.752+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T144155, end_date=20250718T144155
[2025-07-18T14:41:55.759+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 187)
[2025-07-18T14:41:55.790+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:41:55.805+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:43:11.023+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:43:11.028+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:43:11.029+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:43:11.029+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:43:11.029+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:43:11.036+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:43:11.039+0000] {standard_task_runner.py:55} INFO - Started process 177 to run task
[2025-07-18T14:43:11.042+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpqbg33eeo']
[2025-07-18T14:43:11.043+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:43:11.083+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 1ebd788c019e
[2025-07-18T14:43:11.127+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:43:11.128+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:43:11.128+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:43:11.135+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:43:11.199+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:43:11.201+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:43:11.201+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:43:11.201+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:43:11.201+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:43:11.209+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:43:11.211+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T144311, end_date=20250718T144311
[2025-07-18T14:43:11.218+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 177)
[2025-07-18T14:43:11.223+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:43:11.239+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:45:05.574+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:45:05.580+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:45:05.580+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:45:05.580+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:45:05.580+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:45:05.587+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:45:05.590+0000] {standard_task_runner.py:55} INFO - Started process 177 to run task
[2025-07-18T14:45:05.593+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp2cg093df']
[2025-07-18T14:45:05.594+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:45:05.640+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 4ca870d615c4
[2025-07-18T14:45:05.693+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:45:05.694+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:45:05.695+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:45:05.700+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:45:05.759+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:45:05.761+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:45:05.761+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:45:05.762+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:45:05.762+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:45:05.769+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:45:05.772+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T144505, end_date=20250718T144505
[2025-07-18T14:45:05.779+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 177)
[2025-07-18T14:45:05.814+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:45:05.831+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:47:14.275+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:47:14.280+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:47:14.281+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:47:14.281+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:47:14.281+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:47:14.287+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:47:14.290+0000] {standard_task_runner.py:55} INFO - Started process 186 to run task
[2025-07-18T14:47:14.292+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmplzrukhqh']
[2025-07-18T14:47:14.294+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:47:14.342+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 9800c2871322
[2025-07-18T14:47:14.390+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:47:14.391+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:47:14.391+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:47:14.398+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:47:14.459+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:47:14.460+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:47:14.460+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:47:14.460+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:47:14.461+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:47:14.469+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:47:14.471+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T144714, end_date=20250718T144714
[2025-07-18T14:47:14.477+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 186)
[2025-07-18T14:47:14.513+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:47:14.527+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:48:43.753+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:48:43.759+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:48:43.759+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:48:43.759+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:48:43.759+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:48:43.766+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:48:43.770+0000] {standard_task_runner.py:55} INFO - Started process 177 to run task
[2025-07-18T14:48:43.772+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp811lbzxu']
[2025-07-18T14:48:43.773+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:48:43.826+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host d3bf36d284c0
[2025-07-18T14:48:43.872+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:48:43.873+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:48:43.874+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:48:43.883+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:48:43.946+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:48:43.946+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:48:43.946+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:48:43.946+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:48:43.948+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:48:43.954+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:48:43.956+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T144843, end_date=20250718T144843
[2025-07-18T14:48:43.963+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 177)
[2025-07-18T14:48:43.996+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:48:44.015+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:50:15.146+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:50:15.151+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:50:15.152+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:50:15.152+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:50:15.152+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:50:15.158+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:50:15.163+0000] {standard_task_runner.py:55} INFO - Started process 177 to run task
[2025-07-18T14:50:15.165+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpcnoz0xe2']
[2025-07-18T14:50:15.167+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:50:15.212+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host a5faf2a6bdf6
[2025-07-18T14:50:15.255+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:50:15.255+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:50:15.256+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:50:15.262+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:50:15.316+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:50:15.317+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:50:15.317+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:50:15.317+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:50:15.318+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:50:15.325+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:50:15.327+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T145015, end_date=20250718T145015
[2025-07-18T14:50:15.335+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 177)
[2025-07-18T14:50:15.345+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:50:15.360+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:51:21.390+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:51:21.396+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:51:21.396+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:51:21.396+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:51:21.399+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:51:21.407+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:51:21.411+0000] {standard_task_runner.py:55} INFO - Started process 178 to run task
[2025-07-18T14:51:21.413+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpo84wb0j1']
[2025-07-18T14:51:21.415+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:51:21.454+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 7b35b459fda6
[2025-07-18T14:51:21.497+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:51:21.497+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:51:21.498+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:51:21.504+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:51:21.554+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:51:21.555+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:51:21.556+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:51:21.556+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:51:21.556+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:51:21.564+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:51:21.566+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T145121, end_date=20250718T145121
[2025-07-18T14:51:21.572+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 178)
[2025-07-18T14:51:21.593+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:51:21.608+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T14:55:23.261+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:55:23.266+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T14:55:23.266+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:55:23.267+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T14:55:23.267+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T14:55:23.274+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T14:55:23.277+0000] {standard_task_runner.py:55} INFO - Started process 177 to run task
[2025-07-18T14:55:23.279+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpij0z7nvf']
[2025-07-18T14:55:23.281+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T14:55:23.331+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host aede2927957c
[2025-07-18T14:55:23.389+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T14:55:23.391+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T14:55:23.392+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T14:55:23.425+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T14:55:23.485+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T14:55:23.487+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T14:55:23.487+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T14:55:23.487+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T14:55:23.488+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T14:55:23.495+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T14:55:23.497+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T145523, end_date=20250718T145523
[2025-07-18T14:55:23.504+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 177)
[2025-07-18T14:55:23.546+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T14:55:23.561+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:07:43.613+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:07:43.623+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:07:43.623+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:07:43.623+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:07:43.623+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:07:43.632+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:07:43.635+0000] {standard_task_runner.py:55} INFO - Started process 188 to run task
[2025-07-18T15:07:43.637+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpblcat3gy']
[2025-07-18T15:07:43.639+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:07:43.688+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host a219ba5834e6
[2025-07-18T15:07:43.730+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:07:43.731+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:07:43.731+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:07:43.740+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:07:44.708+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T15:07:44.709+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 3, in <module>
[2025-07-18T15:07:44.710+0000] {subprocess.py:93} INFO -     from src.data.ingestion import DataIngestor
[2025-07-18T15:07:44.711+0000] {subprocess.py:93} INFO -   File "/app/src/data/ingestion.py", line 3, in <module>
[2025-07-18T15:07:44.711+0000] {subprocess.py:93} INFO -     from sklearn.datasets import fetch_openml
[2025-07-18T15:07:44.711+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'sklearn'
[2025-07-18T15:07:44.826+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T15:07:44.842+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T15:07:44.845+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T150743, end_date=20250718T150744
[2025-07-18T15:07:44.861+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 188)
[2025-07-18T15:07:44.885+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T15:07:44.913+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:14:11.565+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:14:11.571+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:14:11.571+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:14:11.571+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:14:11.572+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:14:11.581+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:14:11.585+0000] {standard_task_runner.py:55} INFO - Started process 183 to run task
[2025-07-18T15:14:11.587+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmplu249lrt']
[2025-07-18T15:14:11.589+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:14:11.640+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host a5d11e1eb97a
[2025-07-18T15:14:11.688+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:14:11.691+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:14:11.692+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:14:11.697+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:14:11.750+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T15:14:11.752+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T15:14:11.752+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T15:14:11.752+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T15:14:11.752+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T15:14:11.759+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T15:14:11.761+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T151411, end_date=20250718T151411
[2025-07-18T15:14:11.768+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 183)
[2025-07-18T15:14:11.810+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T15:14:11.827+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:15:56.104+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:15:56.109+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:15:56.109+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:15:56.109+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:15:56.109+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:15:56.120+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:15:56.124+0000] {standard_task_runner.py:55} INFO - Started process 178 to run task
[2025-07-18T15:15:56.127+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpj_wb3rnu']
[2025-07-18T15:15:56.128+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:15:56.179+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host ba497a15e31c
[2025-07-18T15:15:56.225+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:15:56.225+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:15:56.226+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:15:56.232+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:15:56.281+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T15:15:56.283+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T15:15:56.283+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T15:15:56.284+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T15:15:56.286+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T15:15:56.295+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T15:15:56.298+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T151556, end_date=20250718T151556
[2025-07-18T15:15:56.306+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 178)
[2025-07-18T15:15:56.311+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T15:15:56.325+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:17:05.663+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:17:05.669+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:17:05.669+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:17:05.670+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:17:05.670+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:17:05.681+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:17:05.685+0000] {standard_task_runner.py:55} INFO - Started process 177 to run task
[2025-07-18T15:17:05.687+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmps3hhkcl9']
[2025-07-18T15:17:05.689+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:17:05.737+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host efbb05f14c65
[2025-07-18T15:17:05.782+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:17:05.782+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:17:05.783+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:17:05.790+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:17:05.853+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T15:17:05.854+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T15:17:05.854+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T15:17:05.854+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T15:17:05.855+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T15:17:05.862+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/bash.py", line 197, in execute
    f"Bash command failed. The command returned a non-zero exit code {result.exit_code}."
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T15:17:05.864+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T151705, end_date=20250718T151705
[2025-07-18T15:17:05.872+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 177)
[2025-07-18T15:17:05.907+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T15:17:05.923+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:19:43.695+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:19:43.708+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:19:43.710+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:19:43.710+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:19:43.710+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:19:43.721+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:19:43.728+0000] {standard_task_runner.py:55} INFO - Started process 171 to run task
[2025-07-18T15:19:43.732+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpje4ehtu6']
[2025-07-18T15:19:43.734+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:19:43.794+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 01b5835eb14c
[2025-07-18T15:19:43.838+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:19:43.840+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:19:43.840+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:19:43.848+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:19:43.972+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T15:19:43.973+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 1, in <module>
[2025-07-18T15:19:43.973+0000] {subprocess.py:93} INFO -     import hydra
[2025-07-18T15:19:43.973+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'hydra'
[2025-07-18T15:19:43.975+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T15:19:43.983+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 196, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T15:19:43.985+0000] {taskinstance.py:1322} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T151943, end_date=20250718T151943
[2025-07-18T15:19:43.993+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 171)
[2025-07-18T15:19:44.037+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T15:19:44.054+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:21:37.643+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:21:37.648+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:21:37.650+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:21:37.651+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:21:37.651+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:21:37.658+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:21:37.664+0000] {standard_task_runner.py:55} INFO - Started process 216 to run task
[2025-07-18T15:21:37.668+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpcc6jzm29']
[2025-07-18T15:21:37.676+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:21:37.785+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 5bd3d7cd7066
[2025-07-18T15:21:37.831+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:21:37.833+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:21:37.833+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:21:37.839+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:21:39.210+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T15:21:39.210+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T15:21:39.210+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T15:21:39.211+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T15:21:39.213+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T15:21:39.307+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T15:21:39.307+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T15:21:39.307+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T15:21:41.009+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T15:21:41.010+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T15:21:41.125+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T15:21:41.146+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T152137, end_date=20250718T152141
[2025-07-18T15:21:41.193+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T15:21:41.213+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:24:51.229+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:24:51.234+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:24:51.234+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:24:51.235+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:24:51.235+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:24:51.242+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:24:51.247+0000] {standard_task_runner.py:55} INFO - Started process 214 to run task
[2025-07-18T15:24:51.249+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp44gwrhxm']
[2025-07-18T15:24:51.252+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:24:51.301+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 25988e3bb701
[2025-07-18T15:24:51.355+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:24:51.356+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:24:51.357+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:24:51.367+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:24:52.431+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T15:24:52.434+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T15:24:52.434+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T15:24:52.435+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T15:24:52.435+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T15:24:52.529+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T15:24:52.532+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T15:24:52.532+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T15:24:54.217+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T15:24:54.218+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T15:24:54.466+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T15:24:54.502+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T152451, end_date=20250718T152454
[2025-07-18T15:24:54.566+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T15:24:54.627+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:32:18.036+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:32:18.045+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:32:18.046+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:32:18.046+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:32:18.049+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:32:18.057+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:32:18.062+0000] {standard_task_runner.py:55} INFO - Started process 221 to run task
[2025-07-18T15:32:18.064+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp_v_mrk6g']
[2025-07-18T15:32:18.067+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:32:18.167+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 95d08d32c22b
[2025-07-18T15:32:18.219+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:32:18.220+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:32:18.220+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:32:18.225+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:32:19.215+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T15:32:19.215+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T15:32:19.215+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T15:32:19.216+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T15:32:19.216+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T15:32:19.314+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T15:32:19.314+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T15:32:19.314+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T15:32:21.027+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T15:32:21.028+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T15:32:21.252+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T15:32:21.286+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T153218, end_date=20250718T153221
[2025-07-18T15:32:21.330+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T15:32:21.356+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:44:29.188+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:44:29.195+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:44:29.195+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:44:29.195+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:44:29.195+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:44:29.203+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:44:29.210+0000] {standard_task_runner.py:55} INFO - Started process 214 to run task
[2025-07-18T15:44:29.212+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpd8u7v9dx']
[2025-07-18T15:44:29.215+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:44:29.316+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host d7e53b8a5638
[2025-07-18T15:44:29.502+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:44:29.506+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:44:29.507+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:44:29.522+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:44:30.825+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T15:44:30.826+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T15:44:30.828+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T15:44:30.829+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T15:44:30.829+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T15:44:30.927+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T15:44:30.929+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T15:44:30.931+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T15:44:32.671+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T15:44:32.674+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T15:44:32.857+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T15:44:32.897+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T154429, end_date=20250718T154432
[2025-07-18T15:44:32.953+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T15:44:32.980+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:46:11.131+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:46:11.147+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:46:11.147+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:46:11.151+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:46:11.151+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:46:11.168+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:46:11.173+0000] {standard_task_runner.py:55} INFO - Started process 216 to run task
[2025-07-18T15:46:11.176+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp1_43br4a']
[2025-07-18T15:46:11.178+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:46:11.239+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 1fae15ff5f05
[2025-07-18T15:46:11.288+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:46:11.290+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:46:11.291+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:46:11.298+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:46:12.403+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T15:46:12.403+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T15:46:12.403+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T15:46:12.403+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T15:46:12.403+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T15:46:12.516+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T15:46:12.522+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T15:46:12.522+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T15:46:14.354+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T15:46:14.355+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T15:46:14.483+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T15:46:14.530+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T154611, end_date=20250718T154614
[2025-07-18T15:46:14.584+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T15:46:14.620+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:51:00.640+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:51:00.647+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:51:00.647+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:51:00.647+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:51:00.647+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:51:00.655+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:51:00.659+0000] {standard_task_runner.py:55} INFO - Started process 215 to run task
[2025-07-18T15:51:00.662+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp2w5trrgp']
[2025-07-18T15:51:00.664+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:51:00.717+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 5e35c0550fc7
[2025-07-18T15:51:00.760+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:51:00.761+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:51:00.770+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:51:00.777+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:51:00.877+0000] {subprocess.py:93} INFO - python: can't open file '/app/scripts/ingest.py': [Errno 2] No such file or directory
[2025-07-18T15:51:00.881+0000] {subprocess.py:97} INFO - Command exited with return code 2
[2025-07-18T15:51:00.887+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 196, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2025-07-18T15:51:00.891+0000] {taskinstance.py:1322} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T155100, end_date=20250718T155100
[2025-07-18T15:51:00.897+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 2.; 215)
[2025-07-18T15:51:00.926+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T15:51:00.942+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:53:43.849+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:53:43.855+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:53:43.856+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:53:43.857+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:53:43.857+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:53:43.868+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:53:43.873+0000] {standard_task_runner.py:55} INFO - Started process 216 to run task
[2025-07-18T15:53:43.881+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmpn9ss0n1z']
[2025-07-18T15:53:43.888+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:53:43.979+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host 4433e9d01b82
[2025-07-18T15:53:44.041+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:53:44.043+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:53:44.043+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:53:44.050+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:53:44.340+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-07-18T15:53:44.340+0000] {subprocess.py:93} INFO -   File "/app/scripts/ingest.py", line 3, in <module>
[2025-07-18T15:53:44.340+0000] {subprocess.py:93} INFO -     from src.data.ingestion import DataIngestor
[2025-07-18T15:53:44.340+0000] {subprocess.py:93} INFO - ModuleNotFoundError: No module named 'src'
[2025-07-18T15:53:44.352+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-07-18T15:53:44.360+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/bash.py", line 196, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-07-18T15:53:44.363+0000] {taskinstance.py:1322} INFO - Marking task as UP_FOR_RETRY. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T155343, end_date=20250718T155344
[2025-07-18T15:53:44.369+0000] {standard_task_runner.py:100} ERROR - Failed to execute job 2 for task ingest_data (Bash command failed. The command returned a non-zero exit code 1.; 216)
[2025-07-18T15:53:44.404+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2025-07-18T15:53:44.419+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-07-18T15:54:54.446+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:54:54.451+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [queued]>
[2025-07-18T15:54:54.451+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:54:54.451+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 2
[2025-07-18T15:54:54.451+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2025-07-18T15:54:54.458+0000] {taskinstance.py:1304} INFO - Executing <Task(BashOperator): ingest_data> on 2025-07-17 00:00:00+00:00
[2025-07-18T15:54:54.466+0000] {standard_task_runner.py:55} INFO - Started process 214 to run task
[2025-07-18T15:54:54.470+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'mlops_retrain_pipeline', 'ingest_data', 'scheduled__2025-07-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/retrain_dag.py', '--cfg-path', '/tmp/tmp6swmy9dc']
[2025-07-18T15:54:54.472+0000] {standard_task_runner.py:83} INFO - Job 2: Subtask ingest_data
[2025-07-18T15:54:54.528+0000] {task_command.py:389} INFO - Running <TaskInstance: mlops_retrain_pipeline.ingest_data scheduled__2025-07-17T00:00:00+00:00 [running]> on host e1a2c151e318
[2025-07-18T15:54:54.632+0000] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=mlops_retrain_pipeline
AIRFLOW_CTX_TASK_ID=ingest_data
AIRFLOW_CTX_EXECUTION_DATE=2025-07-17T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-07-17T00:00:00+00:00
[2025-07-18T15:54:54.633+0000] {subprocess.py:63} INFO - Tmp dir root location: 
 /tmp
[2025-07-18T15:54:54.634+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'python /app/scripts/ingest.py mode=ingest']
[2025-07-18T15:54:54.640+0000] {subprocess.py:86} INFO - Output:
[2025-07-18T15:54:55.727+0000] {subprocess.py:93} INFO - /app/scripts/ingest.py:5: UserWarning:
[2025-07-18T15:54:55.730+0000] {subprocess.py:93} INFO - The version_base parameter is not specified.
[2025-07-18T15:54:55.730+0000] {subprocess.py:93} INFO - Please specify a compatability version level, or None.
[2025-07-18T15:54:55.731+0000] {subprocess.py:93} INFO - Will assume defaults for version 1.1
[2025-07-18T15:54:55.732+0000] {subprocess.py:93} INFO -   @hydra.main(config_path="../config", config_name="config")
[2025-07-18T15:54:55.918+0000] {subprocess.py:93} INFO - /home/***/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
[2025-07-18T15:54:55.918+0000] {subprocess.py:93} INFO - See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
[2025-07-18T15:54:55.918+0000] {subprocess.py:93} INFO -   ret = run_job(
[2025-07-18T15:54:57.470+0000] {subprocess.py:93} INFO - Fetching Adult dataset from OpenML...
[2025-07-18T15:54:57.472+0000] {subprocess.py:93} INFO - ✔ Raw data saved to data/raw/adult.csv
[2025-07-18T15:54:57.590+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2025-07-18T15:54:57.640+0000] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=mlops_retrain_pipeline, task_id=ingest_data, execution_date=20250717T000000, start_date=20250718T155454, end_date=20250718T155457
[2025-07-18T15:54:57.669+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2025-07-18T15:54:57.712+0000] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
